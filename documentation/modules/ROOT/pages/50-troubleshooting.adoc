= Troubleshooting
include::_attributes.adoc[]

As we move forward to our final phase, we enter the Troubleshooting Section. Here, we provide you with essential tools and techniques to tackle any issues that come your way. As an administrator of the infrastructure, you'll master the art of collecting cluster information for effective debugging. Join us in this enlightening section to strengthen your troubleshooting skills and enhance your cache optimization abilities.

Let's start by collecting important details about the Openshift setup, including CRDs, and pod logs and events. Then, we'll dig into examining the Data Grid server, getting the caches' configuration and a complete server report. Lastly, we'll focus on JVM debugging, getting info from the Java Heap Dump and Java Thread Dump.


== Collecting Openshift resources

Ok, we don't know yet what is going on. This section will help us to identify all the components of our installation and give us a methodic way of examining issues.

=== Retrieving the list of server pods

This might seem trivial, but we need to list the pods to then execute other commands inside the pods. Execute the following command to retrieve the full list of pods:

.Get the full list of pods
[.console-input]
[source, bash]
----
oc get pods -l user=$YOUR_USER
----

.Output
[.console-output]
[source, bash]
----
NAME        READY   STATUS    RESTARTS   AGE
cluster-0   1/1     Running   0          19m
cluster-1   1/1     Running   0          19m
----


=== Retrieving all the logs for investigation

Here you have to take into account that three main components take part in the configuration and you should know their responsibilities:

* `infinispan-operator-controller-manager`: This is the operator itself and runs in this workshop in a different namespace named `rhdg-operator`. It synchronizes the configuration of the CRDs with Openshift objects and the Infinispan server itself. There is an exception for the Cache CRD when the `.spec.configListener.enabled` = true in the Infinispan CRD - which is enabled by default-, this sync is delegated to the config-listener deployed for each cluster.
+
.Check the logs of the operator pod
[.console-input]
[source, bash]
----
oc logs -f $(oc get pods -n rhdg-operator --template="{{(index .items 0).metadata.name }}") -n rhdg-operator
----
+
* `cluster-config-listener`: There is one per cluster and it can be disabled when `.spec.configListener.enabled` = false in the Infinispan CRD. It is responsible for the bidirectional reconciliation of cache configurations between the Data Grid server and the Cache CRD. 
+
.Check the logs of the config-listener pod
[.console-input]
[source, bash]
----
oc logs -f $(oc get pods -l app=infinispan-config-listener-pod --template="{{(index .items 0).metadata.name }}")
----
+
* `cluster-pods`: These are the actual pods of the cluster. In its logs, you can see issues related to server configuration, the clustering based on JGroups, and access logs.
+
.Check the logs of the server pods
[.console-input]
[source, bash]
----
oc logs -f cluster-0
----




=== Retrieving the Openshift configuration

This information is essential for the Data Grid support team to have a clear idea of the issue that you are facing. The recommended way to collect information is using the inspect command:


.Get the full report of the namespace
[.console-input]
[source, bash]
----
oc adm inspect namespace/$YOUR_USER-rhdg
----

If you don't have enough permissions to execute the above command, you will need that information manually.

The `oc adm inspect` command does not collect Custom resources. Therefore, you will need to collect the separately:

.Get the custom resources
[.console-input]
[source, bash]
----
oc get infinispan -o yaml > infinispan.yaml

oc get cache -o yaml > caches.yaml
----




== The Data Grid server report

Data Grid Server provides aggregated reports in tar.gz archives that contain diagnostic information about server instances and host systems. The report provides details about CPU, memory, open files, network sockets and routing, and threads, in addition to configuration and log files.

Retrieving the server report takes several steps, as you have to use the Infinispan CLI. In the following command, I have automated the process so that you can generate it and download it easily:

.Get the server report
[.console-input]
[source, bash]
----
# Generate the report
oc exec cluster-0 -- bash -c 'echo "server report" | ./bin/cli.sh --trustall -c https://admin:password@$HOSTNAME:11222 -f -'
# Download the report
oc exec cluster-0 -- bash -c 'files=( *tar.gz* ); cat "${files[0]}"' > $(date +"%Y-%m-%d-%H-%M")-cluster-0-report.tar.gz
----

The report comprises the execution of several useful commands that will help you understand the reasons why the server might be misconfigured:

.Server report output
[.console-output]
[source, bash]
----
$ ls -1 cluster-0-report
    184
    conf
    cpuinfo
    data
    df
    ip-address
    ip-maddress
    ip-mroute
    ip-route
    log
    lsof
    meminfo
    os-release
    ss-tcp
    ss-udp
    uname
----





== Using the REST API to retrieve information from the cluster

This section compiles a set of REST endpoints useful to retrieve configuration from the server.

TIP: Some of the objects of this section might be new to you: Proto files, server tasks, indexes, etc. Do not worry, these commands will be useful for you for the Advanced Exercises Section.

The following REST requests have been done using the `curl` command, adapt it to any method you consider more convenient.

[IMPORTANT]
====
You need to define the env var with the REST Endpoint before executing the next commands:

.Set Data Grid server URL
[.console-input]
[source, bash]
----
RHDG_URL=$(oc get routes --template='https://{{(index .items 0).spec.host }})
----

====



=== Problems with Server Config?

You can retrieve the actual configuration of the Red Hat Data Grid server. As you know, the final configuration is the result of a merge operation between several configuration files. You can see all of them checking the command executed in the JVM (First line of the pod logs).

If you want to show the resulting configuration, execute the following command:

.Curl command to retrieve Server Config
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/server/config | yq -P .
----



=== Problems with Protobuf? 


You can list all the `.proto` files and also all the Proto types using the REST API.


.Curl command to retrieve the Proto files
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/schemas | jq .
----

.Curl command to retrieve the Proto Types (Primitives)
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/schemas?action=types | jq .
----


=== Problems with cache definitions? 

At some point, you will want to know if a certain cache name is configured in the cluster, or if the cache definition was correctly applied. You can check the status and configuration of the caches with the following commands:

.Get all caches
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches | jq .
----


.Check the status of the cluster and all the caches
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/cache-managers/default/health | jq .
----


.Check cache config and stats
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01 | yq -P .
----




=== Problems with Server tasks? 

You can also define Server Tasks in Java and load them on the server. Then, you will be able to execute them using REST or Hot Rod. You can list the Server tasks with the following REST call:

.List all the available Server Tasks
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/tasks | jq .
----


=== Problems with the content of a cache?

You can also fully interact with the cache, creating, modifying, listing and removing contents of every cache compatible with the REST interface (For example, you cannot create Java Serialized objects). Here we list some commands to get the status and debug issues. Go to the Exercises section for more tasks about the REST endpoint.

.List all the entries of the cache
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01?action=entries | jq .
----

.Clear a cache
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -X POST -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01?action=clear
----



=== Problems with indexes and queries?


Queries and indexes also provide some specific endpoints for debugging and reconfiguration. First, queries are executed over indexed caches. When you delete fields or change index field definitions, you must rebuild the index to ensure the index is consistent with the data in the cache. You can do that using the following endpoint:


.Reindex a cache.
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -X POST -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01/search/indexes?action=reindex
----


Once you begin to execute queries over the cache, you will be interested in debugging based on statistics. Obtain information about queries and indexes in caches with GET requests:

 

.Get cache index and query statistics
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01/search/stats | jq .
----







== Adjusting log levels

Change levels for different Data Grid logging categories when you need to debug issues. You can also adjust log levels to reduce the number of messages for certain categories to minimize the use of container resources. You can try to change the logging configuration without restarting by adding the following lines in the Infinispan CR:


.Add custom log levels
[.console-input]
[source, yaml]
----
apiVersion: infinispan.org/v1
kind: Infinispan
metadata:
  name: cluster
spec:
  logging:
    categories:
      org.infinispan.REST_ACCESS_LOG: trace
----

Then, you can execute the following query and you will see that access logs per REST call are only logged to stdout if `REST_ACCESS_LOG` = `trace`:

.Get cache index and query statistics
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01?action=entries
----








== JVM debugging


=== Java Thread Dump


A *Java thread dump* is a snapshot of what every thread in the JVM is doing at a particular point in time. Each thread in the JVM is listed with its name and ID, its current state and the Java call stack showing what monitor it has locked or is waiting on.



.Get a Thread Dump
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/server/threads
----



=== Java Heap Dump

A *Java Heap Dump* is a snapshot of all the objects that are in memory in the JVM at a certain moment. They are very useful for troubleshooting memory leak problems and optimizing memory usage in Java applications. Heap dumps are usually stored in binary format `hprof` files.


.Get a Heap Dump
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -X POST -s -k -u admin:password $RHDG_URL/rest/v2/server/memory?action=heap-dump
# Take the filename from the output to copy it to your machine
oc cp cluster-0:/opt/infinispan/server/data/$DUMP_FILENAME.prof . heapdump-cluster-0.hprof
----



=== Logging GC messages

The Data Grid Operator does not log Garbage Collector (GC) messages by default. You can direct GC messages to stdout with the following JVM options:


.Configure GC messages to stdout
[.console-input]
[source, yaml]
----
apiVersion: infinispan.org/v1
kind: Infinispan
metadata:
  name: cluster
spec:
  container:
    # If you want to keep the timezone config, just append the following to the existing config
    extraJvmOpts: "-Xlog:gc*:stdout:time,level,tags"
----

If instead, you want the logs in a separate file (as it might be quite verbose), you can use a configuration like the following:

.Configure GC messages to file
[.console-input]
[source, yaml]
----
apiVersion: infinispan.org/v1
kind: Infinispan
metadata:
  name: cluster
spec:
  container:
    # If you want to keep the timezone config, just append the following to the existing config
    extraJvmOpts: "-Xlog:gc*=info:file=/tmp/gc.log:time,level,tags,uptimemillis:filecount=10,filesize=1m"
----



=== Analyzing File descriptions

A file descriptor is a number that uniquely identifies an open file in a computer's operating system. It describes a data resource, and how that resource may be accessed. It is needed to open *files*, *network sockets*, etc. There is a *default limit* to the number of opened file descriptors. If you suspect that you are matching that limit, you can check with the following command:

.Get the opened file descriptors
[.console-input]
[source, bash]
----
oc exec cluster-0 -- lsof -P > lsof-cluster-0.txt
----










== Converting Cache definitions using the REST API

Do you like a specific format to define caches (YAML, XML, JSON), but you found a tutorial with a cache definitionin a different format and would like to convert it? That's easy! There are two use cases here. 

If the cache is already in a cluster, you can retrieve it in any of the three formats just sending the proper header. Let's use the same cache as in previous exercises:


.Get Cache Definition in different formats
[.console-input]
[source, bash]
----
# Accept YAML
curl -s -k -u admin:password -H "Accept: application/yaml" $RHDG_URL/rest/v2/caches/cache-replicated-01?action=config
# Accept XML
curl -s -k -u admin:password -H "Accept: application/xml" $RHDG_URL/rest/v2/caches/cache-replicated-01?action=config
# Accept JSON
curl -s -k -u admin:password -H "Accept: application/json" $RHDG_URL/rest/v2/caches/cache-replicated-01?action=config
----

However, if the cache is not present in the cluster, you can use the convert action of the caches endpoint: 

.Conver from XML to YAML
[.console-input]
[source, bash]
----
curl $RHDG_URL/rest/v2/caches?action=convert \
  --digest -u admin:password \
  -X POST -k \
  -H "Accept: application/yaml" \
  -H "Content-Type: application/xml" \
  -d '<?xml version="1.0" encoding="UTF-8"?><replicated-cache mode="SYNC" statistics="false"><encoding media-type="application/x-protostream"/><expiration lifespan="300000" /><memory max-size="400MB" when-full="REMOVE"/><state-transfer enabled="true" await-initial-transfer="false"/></replicated-cache>'
----

TIP: This endpoint also validates the cache configuration and migrates from deprecated parameters to up-to-date ones!!


== Useful KCS

Do you have other needs and you would like to have the `jcmd` command inside the pod? Try the documentation of this KCS:

* KCS: https://access.redhat.com/solutions/6964022[Alternatives for creating heap dump and thread dump in a DG 8 even without the JDK].
* KCS: https://access.redhat.com/solutions/6968671[Troubleshoot options for Data Grid pod crash].
* KCS: https://access.redhat.com/solutions/6962483[Using inspect for DG 8 troubleshooting].
* KCS: https://access.redhat.com/solutions/6452611[DG 8 Troubleshooting steps for issues in OCP 4].
