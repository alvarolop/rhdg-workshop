= Troubleshooting
include::_attributes.adoc[]

As we move forward to our final phase, we enter the Troubleshooting Section. Here, we provide you with essential tools and techniques to tackle any issues that come your way. As an administrator of the infrastructure, you'll master the art of collecting cluster information for effective debugging. Join us in this enlightening section to strengthen your troubleshooting skills and enhance your cache optimization abilities.

Let's start by collecting important details about the Openshift setup, including CRDs, and pod logs and events. Then, we'll dig into examining the Data Grid server, getting the caches' configuration and a complete server report. Lastly, we'll focus on JVM debugging, getting info from the Java Heap Dump and Java Thread Dump.


== Collecting Openshift resources

Ok, we don't know yet what is going on. This section will help us to identify all the components of our installation and give us a methodic way of examining issues.

=== Retrieving the list of server pods

This might seem trivial, but we need to list the pods to then execute other commands inside the pods. Execute the following command to retrieve the full list of pods:

.Get the full list of pods
[.console-input]
[source, bash]
----
oc get pods -l user=$YOUR_USER
----

.Output
[.console-output]
[source, bash]
----
NAME        READY   STATUS    RESTARTS   AGE
cluster-0   1/1     Running   0          19m
cluster-1   1/1     Running   0          19m
----


=== Retrieving all the logs for investigation

Here you have to take into account that three main components take part in the configuration and you should know their responsibilities:

* `infinispan-operator-controller-manager`: This is the operator itself and runs in this workshop in a different namespace named `rhdg-operator`. It synchronizes the configuration of the CRDs with Openshift objects and the Infinispan server itself. There is an exception for the Cache CRD when the `.spec.configListener.enabled` = true in the Infinispan CRD - which is enabled by default-, this sync is delegated to the config-listener deployed for each cluster.
+
.Check the logs of the operator pod
[.console-input]
[source, bash]
----
oc logs -f $(oc get pods -n rhdg-operator --template="{{(index .items 0).metadata.name }}") -n rhdg-operator
----
+
* `cluster-config-listener`: There is one per cluster and it can be disabled when `.spec.configListener.enabled` = false in the Infinispan CRD. It is responsible for the bidirectional reconciliation of cache configurations between the Data Grid server and the Cache CRD. 
+
.Check the logs of the config-listener pod
[.console-input]
[source, bash]
----
oc logs -f $(oc get pods -l app=infinispan-config-listener-pod --template="{{(index .items 0).metadata.name }}")
----
+
* `cluster-pods`: These are the actual pods of the cluster. In its logs, you can see issues related to server configuration, the clustering based on JGroups, and access logs.
+
.Check the logs of the server pods
[.console-input]
[source, bash]
----
oc logs -f cluster-0
----




=== Retrieving the Openshift configuration

This information is essential for the Data Grid support team to have a clear idea of the issue that you are facing. The recommended way to collect information is using the inspect command:


.Get the full report of the namespace
[.console-input]
[source, bash]
----
oc adm inspect namespace/$YOUR_USER-rhdg
----

If you don't have enough permissions to execute the above command, you will need that information manually.





== The Data Grid server report

Data Grid Server provides aggregated reports in tar.gz archives that contain diagnostic information about server instances and host systems. The report provides details about CPU, memory, open files, network sockets and routing, and threads, in addition to configuration and log files.

Retrieving the server report takes several steps, as you have to use the Infinispan CLI. In the following command, I have automated the process so that you can generate it and download it easily:

.Get the server report
[.console-input]
[source, bash]
----
# Generate the report
oc exec cluster-0 -- bash -c 'echo "server report" | ./bin/cli.sh --trustall -c https://admin:password@$HOSTNAME:11222 -f -'
# Download the report
oc exec cluster-0 -- bash -c 'files=( *tar.gz* ); cat "${files[0]}"' > $(date +"%Y-%m-%d-%H-%M")-cluster-0-report.tar.gz
----

The report comprises the execution of several useful commands that will help you understand the reasons why the server might be misconfigured:

.Server report output
[.console-output]
[source, bash]
----
$ ls -1 cluster-0-report
    184
    conf
    cpuinfo
    data
    df
    ip-address
    ip-maddress
    ip-mroute
    ip-route
    log
    lsof
    meminfo
    os-release
    ss-tcp
    ss-udp
    uname
----





== Using the REST API to retrieve information from the cluster

This section compiles a set of REST endpoints useful to retrieve configuration from the server.

TIP: Some of the objects of this section might be new to you: Proto files, server tasks, indexes, etc. Do not worry, these commands will be useful for you for the Advanced Exercises Section.

The following REST requests have been done using the `curl` command, adapt it to any method you consider more convenient.

[IMPORTANT]
====
You need to define the env var with the REST Endpoint before executing the next commands:

.Set Data Grid server URL
[.console-input]
[source, bash]
----
RHDG_URL=$(oc get routes --template='https://{{(index .items 0).spec.host }})
----

====



=== Problems with Server Config?

You can retrieve the actual configuration of the Red Hat Data Grid server. As you know, the final configuration is the result of a merge operation between several configuration files. You can see all of them checking the command executed in the JVM (First line of the pod logs).

If you want to show the resulting configuration, execute the following command:

.Curl command to retrieve Server Config
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/server/config | yq -P .
----



=== Problems with Protobuf? 


You can list all the `.proto` files and also all the Proto types using the REST API.


.Curl command to retrieve the Proto files
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/schemas | jq .
----

.Curl command to retrieve the Proto Types (Primitives)
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/schemas?action=types | jq .
----


=== Problems with cache definitions? 

At some point, you will want to know if a certain cache name is configured in the cluster, or if the cache definition was correctly applied. You can check the status and configuration of the caches with the following commands:

.Get all caches
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches | jq .
----


.Check the status of the cluster and all the caches
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/cache-managers/default/health | jq .
----


.Check cache config and stats
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01 | yq -P .
----




=== Problems with Server tasks? 

You can also define Server Tasks in Java and load them on the server. Then, you will be able to execute them using REST or Hot Rod. You can list the Server tasks with the following REST call:

.List all the available Server Tasks
[.console-input]
[source, bash]
----
curl -s -k -u admin:password $RHDG_URL/rest/v2/tasks | jq .
----


=== Problems with the content of a cache?

You can also fully interact with the cache, creating, modifying, listing and removing contents of every cache compatible with the REST interface (For example, you cannot create Java Serialized objects). Here we list some commands to get the status and debug issues. Go to the Exercises section for more tasks about the REST endpoint.

.List all the entries of the cache
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01?action=entries | jq .
----

.Clear a cache
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -X POST -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01?action=clear
----



=== Problems with indexes and queries?


Queries and indexes also provide some specific endpoints for debugging and reconfiguration. First, queries are executed over indexed caches. When you delete fields or change index field definitions, you must rebuild the index to ensure the index is consistent with the data in the cache. You can do that using the following endpoint:


.Reindex a cache.
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -X POST -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01/search/indexes?action=reindex
----


Once you begin to execute queries over the cache, you will be interested in debugging based on statistics. Obtain information about queries and indexes in caches with GET requests:

 

.Get cache index and query statistics
[.console-input]
[source, bash]
----
# Change "cache-replicated-01" to your desired cache name
curl -s -k -u admin:password $RHDG_URL/rest/v2/caches/cache-replicated-01/search/stats | jq .
----







== Changing logging config without restart



== Converting Cache definitions using the REST API

https://github.com/alvarolop/rhdg8-server#annex-convert-cache-configurations




== JVM debugging


=== Problems with the JVM memory on cluster pods?


* Java Thread Dump
* Java Heap Dump


=== Reached file limit descriptors on a pod?

